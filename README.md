## License 
The project is licensed under the MIT License.

## Citation

If the codebase, dataset or any part of this project is used, please cite the following:

@misc{mogos2025impact,
  author       = {Daria Ana-Maria Mogo»ô},
  title        = {Impact of Accessibility Tools on Developer Productivity},
  year         = {2025},
  url          = {https://github.com/mariamogos/Impact-of-Accessibility-Tools-on-Developer-Productivity},
  note         = {GitHub repository}
}


## Introduction

This repository contains all the scripts, datasets and files for the study titled "Impact of Accessibility Tools on Developer Productivity". The aim of the study was to investigate how the availability of GitHub Copilot may have influenced the productivity of self-indentified disabled developers on GitHub, by comparing two timeframes: pre- and post-release, making use of several statistical and descriptive methods. 

The scripts are organized in multiple folders as such: [clean_up](./clean_up/), [descriptive_analysis](./descriptive_analysis/), [mining](./mining/), [normality_assessment](./normality_assessment/) and [statistical_analysis](./statistical_analysis/).

## Mining

There are two scripts for mining the user activity and bios from GitHub's API.

### mining.py

The script performs initial discovery of GitHub users, who self-indentify with disability-related keywords in their bio, and collects their activity across the two timeframes. 

- Search Terms Used: "disabled", "blind", "visually impaired", "deaf", "neurodivergent", "autistic", "adhd", "chronic illness", "mobility aid"

- Time Periods Compared: October 1-31 2024, March 1-31 2025

- Collected Metrics: number of commits made, number of pull requests created, number of pull requests reviewed

The script outputs a CSV file [dev_productivity_by_period.csv](./datasets/dev_productivity_by_period.csv), which contains the GitHub username, Bio and the three activity metrics in both timeframes.

This script builds the initial dataset of potentially eligible users with any development activity during either timeframe.

### extended_mining.py

After the first dataset from the previous script, we needed to tweak the timeframes to (hopefully) gather more significant data. Therefore, the CSV file [dev_productivity_autumn](./datasets/dev_productivity_autumn.csv) which had 295 users stores their activity August 1 - November 30 2024, compared to January 1 - April 30 2025; the CSV file [dev_productivity_extended](./datasets/dev_productivity_extended.csv) contains the users' activity between January 1 - April 30 2024, January 1 - April 30 2025. Both these CSV files were generated by the same script, by solely modifying the dates.

## Clean-Up and Outlier Detection

### cleanup.py

This script only performs an initial clean-up of the dataset, by applying two filtering criterias:

- Activity: It excludes users who had zerio commits either in the before or after timeframe

- Relevance: Removes the users whose bios do not include any of the keywords in their bios. Because of how the GitHub API works, some users who had the keywords present in their username were also accepted in the first round of mining. At this point in the process we also manually removed any users that used a disability speculatively or as a metaphor. 

### outliers.py

The script identifies and removes outliers from the cleaned dataset using IQR and creates a boxplot of commit activity. The script checks both timeframes and also identifies overlapping outliers. The datasets [users_no_outliers.csv](./clean_dataset/users_no_outliers.csv) and [users_analysis_cleaned.csv](./clean_dataset/users_analysis_cleaned.csv) are further used in our analysis.

## Descriptive analysis

Here all the scripts perform only what their name suggests: we create the distribution of disabilities in our dataset, a histogram of activities both before and after Copilot's release, as well as a barchart to assess possible trends or patterns accross disability groups pre- and post-release.

## Normality

To assess normality we use one script that makes use of two normality tests: Shapiro-Wilk and D'Agostino's K-squared test. We also use Q-Q plots.

## Statistical Analysis
This section contains all the scripts used in the statistical analysis. Each script focuses on a specific test or model to assess the dataset.


## Dependencies

In the file [requirements.txt](./requirements.txt) all Python libraries used in this project can be found.

## How to Run the Scripts
The version of Python used while developing this project is 3.11.6. 

Steps:

- Navigate into the desired folder and run the script by writing the following command in the terminal: `python3 scriptname.py`.

- The order in which scripts are ran matters. The following is the list, in order, of folders as they need to be ran: [mining](./mining/), [clean_up](./clean_up/), and then depending on what the is desired to be tested either run the scripts in the folder [descriptive_analysis](./descriptive_analysis/), or first run the scripts in [normality_assessment](./normality_assessment/) and then [statistical_analysis](./statistical_analysis/)